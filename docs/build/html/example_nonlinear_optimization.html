

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Nonlinear Optimization &mdash; PulsedJAX: Pulse-Retrieval-with-JAX 2025 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=4ae1632d" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css?v=ec38ee01" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=cb975c41"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="_static/copybutton.js?v=f281be69"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Advanced Usage" href="example_advanced_things.html" />
    <link rel="prev" title="Method-Specific Algorithms" href="example_method_specific_algorithms.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            PulsedJAX: Pulse-Retrieval-with-JAX
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Content</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="example_overview_usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_overview_methods.html">Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_overview_algorithms.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_method_specific_algorithms.html">Method-Specific Algorithms</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Nonlinear Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_advanced_things.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="definitions_and_formulas.html">Definitions and Formulas</a><ul>
<li class="toctree-l2"><a class="reference internal" href="eqs_general_definitions.html">General Definitions</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_frog.html">FROG</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_frog.html#interferometric-frog">Interferometric FROG</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_chirpscan.html">Chirp-Scan</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_tdp.html">Time-Domain-Ptychography</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_tdp.html#interferometric-time-domain-ptychography">Interferometric Time-Domain-Ptychography</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_twodsi.html">Two-Dimensional Spectral-Shearing Interferometry (2D-SI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_vampire.html">VAMPIRE</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_pie_grad_hessian.html">PIE - Gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_pie_grad_hessian.html#pie-pseudo-hessian">PIE - Pseudo Hessian</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_s_prime_and_polyak.html">Update nonlinear Signal</a></li>
<li class="toctree-l2"><a class="reference internal" href="eqs_s_prime_and_polyak.html#adaptive-stepsize">Adaptive Stepsize</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="literature.html">Literature</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="frog.html">frog</a></li>
<li class="toctree-l1"><a class="reference internal" href="chirp_scan.html">chirp_scan</a></li>
<li class="toctree-l1"><a class="reference internal" href="tdp.html">tdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="twodsi.html">twodsi</a></li>
<li class="toctree-l1"><a class="reference internal" href="vampire.html">vampire</a></li>
<li class="toctree-l1"><a class="reference internal" href="simulate_trace.html">simulate_trace</a></li>
<li class="toctree-l1"><a class="reference internal" href="real_fields.html">real_fields</a><ul>
<li class="toctree-l2"><a class="reference internal" href="real_fields.chirp_scan.html">real_fields.chirp_scan</a></li>
<li class="toctree-l2"><a class="reference internal" href="real_fields.frog.html">real_fields.frog</a></li>
<li class="toctree-l2"><a class="reference internal" href="real_fields.tdp.html">real_fields.tdp</a></li>
<li class="toctree-l2"><a class="reference internal" href="real_fields.twodsi.html">real_fields.twodsi</a></li>
<li class="toctree-l2"><a class="reference internal" href="real_fields.vampire.html">real_fields.vampire</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="core.html">core</a><ul>
<li class="toctree-l2"><a class="reference internal" href="core.gradients.html">core.gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="core.hessians.html">core.hessians package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utilities.html">utilities</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PulsedJAX: Pulse-Retrieval-with-JAX</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Nonlinear Optimization</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/example_nonlinear_optimization.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="nonlinear-optimization">
<h1>Nonlinear Optimization<a class="headerlink" href="#nonlinear-optimization" title="Link to this heading"></a></h1>
<p>Generalized Projection, PIE and COPRA have been implemented to support various forms of nonlinear optimization techniques. The scope and usage of these are explained in this section.</p>
<section id="linesearch-and-adaptive-stepsize">
<h2>Linesearch and Adaptive-Stepsize<a class="headerlink" href="#linesearch-and-adaptive-stepsize" title="Link to this heading"></a></h2>
<p>In order to accelerate convergence a <code class="docutils literal notranslate"><span class="pre">&quot;backtracking&quot;</span></code> and a <code class="docutils literal notranslate"><span class="pre">&quot;zoom&quot;</span></code> linesearch are implemented  <span id="id1">[<a class="reference internal" href="literature.html#id29" title="Jorge Nocedal and Stephen Wright. Numerical Optimization. Springer New York, New York, NY, 2nd ed. 2006 edition, 2006. ISBN 9780387400655. doi:10.1007/978-0-387-40065-5.">27</a>]</span>. In addition a generalization of the Polyak-Stepsize <span id="id2">[<a class="reference internal" href="literature.html#id28" title="B.T. Polyak. Minimization of unsmooth functionals. USSR Computational Mathematics and Mathematical Physics, 9(3):14-29, 1969. doi:https://doi.org/10.1016/0041-5553(69)90061-5.">28</a>]</span> is available. The implementations are located in <code class="docutils literal notranslate"><span class="pre">pulsedjax.core.stepsize.py</span></code>.<br />
The backtracking linesearch works by reducing the stepsize by a factor until the Armijo-condition is fullfilled or the maximum number of steps is reached. The stepsize is updated via <span class="math notranslate nohighlight">\(\gamma' = \gamma\cdot\Delta\gamma\)</span>. The Armijo-Condition reads:</p>
<p><span class="math notranslate nohighlight">\( \Delta L \leq c_1\gamma\cdot p\top\cdot\nabla L\)</span></p>
<p>where <span class="math notranslate nohighlight">\(\Delta L\)</span> is the change in the error, <span class="math notranslate nohighlight">\(p\)</span> is the descent direction and <span class="math notranslate nohighlight">\(c_1\)</span> is a constant that tunes the condition. In short, the condition checks if the error has decreased beyond a linear approximation whose slope is set by <span class="math notranslate nohighlight">\(c_1\)</span>. As long as <span class="math notranslate nohighlight">\(0&lt;c_1&lt;1\)</span> a stepsize that fulfills the condition should exist.<br />
The zoom-linesearch expands on this by requiring the Strong-Wolfe Condition on top of the Armijo-Condition. This condition reads:</p>
<p><span class="math notranslate nohighlight">\(|p\top\cdot\nabla L'|\leq c_2 |p\top\cdot\nabla L|\)</span></p>
<p>It requires that not only the error has to decrease sufficiently but that also the slope of the error along the search direction should decrease. This enforces a stepsize sufficient to reach close to a minimum along the search direction. The amount of reduction in the slope is controlled via <span class="math notranslate nohighlight">\(c_2\)</span>. In order for a solution to exist <span class="math notranslate nohighlight">\(0&lt;c_1&lt;c_2&lt;1\)</span> is required.<br />
The zoom linesearch works in to phases. A finding-phase and a zoom-phase. In the finding-phase the step size is increased using <span class="math notranslate nohighlight">\(\gamma' = \gamma\cdot\Delta\gamma\)</span>. If the stepsize is increased beyond a minimum along the descent direction the zoom phase begins. In this phase the local minimum is obtained through successive cubic interpolation along the descent direction. In cases where the cubic interpolation fails the algorithm falls back onto a bisection search.</p>
<p>The lineserch parameters can be either set directly as class attributes, or for simplicty via a setter-function as shown below.<br />
It is hardcoded that linesearches will only be performed during global iterations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">algorithm</span><span class="o">.</span><span class="n">set_linesearch</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
                         <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> 
                         <span class="n">c1</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="n">c2</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span> 
                         <span class="n">delta_gamma</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>An alternative to a relative expensive linesearch is presented via an adaptive stepsize, such as the Polyak-Stepsize. The idea is to expand the error function along the descent direction in a Taylor- or Padé-Series. Subsequently a target error <span class="math notranslate nohighlight">\(L'\)</span> can be defined and a stepsize to achieve this error can be obtained. This can be done using a linear or quadratic Taylor expansion or a Padé approximant of order [0/1], [1/1] or [0/2]. In addition a damping factor can be defined which avoids division by zero.<br />
The method and target error reduction can be defined via class attributes or via a setter-function as shown below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">algorithm</span><span class="o">.</span><span class="n">set_adaptive_stepsize</span><span class="p">(</span><span class="n">local_method</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">global_method</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># can be any of &quot;pade_nm&quot;</span>
                                <span class="n">local_factor</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">global_factor</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># -1 is the default for COPRA.</span>
                                <span class="n">damping</span> <span class="o">=</span> <span class="mf">1e-12</span><span class="p">)</span>
        
</pre></div>
</div>
</div>
</div>
</section>
<section id="nonlinear-conjugate-gradient">
<h2>Nonlinear Conjugate-Gradient<a class="headerlink" href="#nonlinear-conjugate-gradient" title="Link to this heading"></a></h2>
<p>The Conjugate Gradient method is used to iteratively solve linear equations. The Nonlinear Conjugate-Gradient Method (NCG, <span id="id3">[<a class="reference internal" href="literature.html#id29" title="Jorge Nocedal and Stephen Wright. Numerical Optimization. Springer New York, New York, NY, 2nd ed. 2006 edition, 2006. ISBN 9780387400655. doi:10.1007/978-0-387-40065-5.">27</a>]</span>) extends heuristically expands this approach to minimize nonlinear equations. The descent direction <span class="math notranslate nohighlight">\(p\)</span> is defined as:</p>
<p><span class="math notranslate nohighlight">\(p_n = -\nabla L + \beta p_{n-1}\)</span></p>
<p>Essentially, if a linesearch is used the error will be minimized along the previous descent direction <span class="math notranslate nohighlight">\(p_{n-1}\)</span>. Thus the steepest descent direction at the new position is perpendicular to <span class="math notranslate nohighlight">\(p_{n-1}\)</span>. Preserving the previous descent direction inhibits a zig-zag motion in the descent and improoves convergence behaviour.<br />
The parameter <span class="math notranslate nohighlight">\(\beta\)</span> can be computed through various formulas which are based on the (linear) Conjugate Gradient method. The available methods to calculate <span class="math notranslate nohighlight">\(\beta\)</span> are <code class="docutils literal notranslate"><span class="pre">&quot;fletcher_reeves&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;polak_ribiere&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;hestenes_stiefel&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;dai_yuan&quot;</span></code>. The implementation of NCG can be found in <code class="docutils literal notranslate"><span class="pre">pulsedjax.core.nonlinear_cg.py</span></code>.<br />
NCG can be enabled as shown below. It does not differentiate between local or global iterations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">algorithm</span><span class="o">.</span><span class="n">nonlinear_conjugate_gradient</span> <span class="o">=</span> <span class="s2">&quot;fletcher_reeves&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="quasi-newton-methods">
<h2>(Quasi)-Newton Methods<a class="headerlink" href="#quasi-newton-methods" title="Link to this heading"></a></h2>
<p>All mentioned algorithms support three Newton-like optimization approaches. One of them is L-BFGS <span id="id4">[<a class="reference internal" href="literature.html#id29" title="Jorge Nocedal and Stephen Wright. Numerical Optimization. Springer New York, New York, NY, 2nd ed. 2006 edition, 2006. ISBN 9780387400655. doi:10.1007/978-0-387-40065-5.">27</a>, <a class="reference internal" href="literature.html#id26" title="Laurent Sorber, Marc Van Barel, and Lieven De Lathauwer. Unconstrained optimization of real functions in complex variables. SIAM Journal on Optimization, 22(3):879-898, 2012. doi:10.1137/110832124.">29</a>]</span>. It is implemented in <code class="docutils literal notranslate"><span class="pre">pulsedjax.core.lbfgs.py</span></code>.<br />
The core idea of BFGS is to avoid an explicit calculation and inversion of the Hessian. Instead the Hessian inverse can be approximated via past gradients. L-BFGS limits the memory of this process to a fixed number of past iterations.</p>
<p>The remaining two are based on the Pseudo-Hessian <span id="id5">[<a class="reference internal" href="literature.html#id27" title="Ken Kreutz-Delgado. The complex gradient operator and the cr-calculus. 2009. URL: https://arxiv.org/abs/0906.4835, arXiv:0906.4835.">30</a>]</span>. Since the search space is complex valued the true hessian is a block matrix of the form:</p>
<p><span class="math notranslate nohighlight">\(H = \begin{bmatrix} \partial_{zz} &amp; \partial_{z\bar{z}} \\\ \partial_{\bar{z}z} &amp; \partial_{\bar{z}\bar{z}} \end{bmatrix}\)</span></p>
<p>where <span class="math notranslate nohighlight">\(\partial_z\)</span> and <span class="math notranslate nohighlight">\(\partial_{\bar{z}}\)</span> refer to the Wirtinger derivatives. In order to relief some numerical burden the Pseudo-Hessian approximates the cross-derivatives as zero.</p>
<p><span class="math notranslate nohighlight">\(H \approx H_{pseudo} = \begin{bmatrix} \partial_{zz} &amp; 0 \\\ 0 &amp; \partial_{\bar{z}\bar{z}} \end{bmatrix}\)</span></p>
<p>Based on this a damped Newton method is implemented. However, since a matrix inverse at each iteration is still quite expensive the Pseudo-Hessian may be approximated via its diagonal.<br />
Thus the available options are <code class="docutils literal notranslate"><span class="pre">&quot;lbfgs&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;diagonal&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;full&quot;</span></code>. In the case of L-BFGS the memory can be tuned. If the full Pseudo-Hessian is used different solver options to calculate the matrix inverse are available. These are <code class="docutils literal notranslate"><span class="pre">&quot;scipy&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;lineax&quot;</span></code> Alternatively a specific lineax-solver can be provided. This includes iterative solvers, which will use a diagonal preconditioner and the previous solution as an initial guess.<br />
The parameters can be controlled as class attributes or via a setter-function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">lineax</span><span class="w"> </span><span class="kn">import</span> <span class="n">GMRES</span>
<span class="n">algorithm</span><span class="o">.</span><span class="n">set_nonlinear_optimization</span><span class="p">(</span><span class="n">local_method</span> <span class="o">=</span> <span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span> <span class="n">global_method</span> <span class="o">=</span> <span class="s2">&quot;full&quot;</span><span class="p">,</span> 
                                     <span class="n">damping</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> 
                                     <span class="n">memory</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> 
                                     <span class="n">solver</span> <span class="o">=</span> <span class="n">GMRES</span><span class="p">(</span><span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">))</span>
        
</pre></div>
</div>
</div>
</div>
</section>
<section id="updating-the-nonlinear-signal-field">
<h2>Updating the nonlinear Signal-Field<a class="headerlink" href="#updating-the-nonlinear-signal-field" title="Link to this heading"></a></h2>
<p>The COPRA <span id="id6">[<a class="reference internal" href="literature.html#id11" title="Nils C. Geib, Matthias Zilk, Thomas Pertsch, and Falk Eilenberger. Common pulse retrieval algorithm: a fast and universal method to retrieve ultrashort pulses. Optica, 6(4):495–505, Apr 2019. doi:10.1364/OPTICA.6.000495.">13</a>]</span> has shown that updating of the nonlinear signal field does not need to be a complete projection in order to perform a successful phase retrieval. Instead an approximate iterative updating is sufficient. In <code class="docutils literal notranslate"><span class="pre">pulsedjax.core.construct_s_prime.py</span></code> the projection as well as the iterative update is implemented such that all algorithms may make use of either one.<br />
In addition an alternative definition to the r-error based on the trace magnitude instead of the intensity as well as an diagonal Newton approximation have been implemented.<br />
The parameters can be controlled as class attributes or via a setter-function. In the case of the latter all attributes are overwritten such that algorithms like COPRA may use <code class="docutils literal notranslate"><span class="pre">&quot;projection&quot;</span></code> by accident.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">algorithm</span><span class="o">.</span><span class="n">set_S_prime_params</span><span class="p">(</span><span class="n">local_method</span> <span class="o">=</span> <span class="s2">&quot;projection&quot;</span><span class="p">,</span> <span class="n">global_method</span> <span class="o">=</span> <span class="s2">&quot;iteration&quot;</span><span class="p">,</span> 
                             <span class="n">gradient</span> <span class="o">=</span> <span class="s2">&quot;intensity&quot;</span><span class="p">,</span> <span class="c1"># &quot;amplitude&quot;</span>
                             <span class="n">newton</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># True for a diagonal Newton step</span>
                             <span class="n">weights</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="c1"># can be an array of the same shape as trace, weights the r-error</span>
                             <span class="n">no_iterations</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># the number of iterations to perform, 1 should be sufficient.</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="example_method_specific_algorithms.html" class="btn btn-neutral float-left" title="Method-Specific Algorithms" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="example_advanced_things.html" class="btn btn-neutral float-right" title="Advanced Usage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Till-Jakob Stehling.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>